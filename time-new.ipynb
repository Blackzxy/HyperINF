{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cOllL4Ms4Ed"
      },
      "source": [
        "## 1. Create DataLoader, Model with LoRA and Influence Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o9YoXLls4Ef"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#### DataLoader\n",
        "task_to_keys = {\n",
        "    \"cola\": (\"sentence\", None),\n",
        "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
        "    \"qnli\": (\"question\", \"sentence\"),\n",
        "    \"qqp\": (\"question1\", \"question2\"),\n",
        "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
        "    \"sst2\": (\"sentence\", None),\n",
        "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
        "}\n",
        "\n",
        "def flip_label(example, ind, noise_index):\n",
        "    '''\n",
        "    Flip the label to make the noisy datapoints\n",
        "    '''\n",
        "    if ind in noise_index:\n",
        "        example[\"label\"] = 1 - example[\"label\"]\n",
        "    return example\n",
        "\n",
        "def load_noisy_dataset_by_task(task=\"mrpc\", noise_ratio=0.1):\n",
        "    glue_datasets = load_dataset(\"glue\", task)\n",
        "    n_train = len(glue_datasets['train'])\n",
        "    n_val = len(glue_datasets['validation'])\n",
        "    if n_train > 4500 and n_val > 500:\n",
        "        new_n_train_list = np.random.choice(n_train, 4500, replace=False)\n",
        "        new_n_val_list = np.random.choice(n_val, 500, replace=False)\n",
        "        glue_datasets['train'] = glue_datasets['train'].select(new_n_train_list)\n",
        "        glue_datasets['validation'] = glue_datasets['validation'].select(new_n_val_list)\n",
        "\n",
        "    n_train = len(glue_datasets['train'])\n",
        "    n_val = len(glue_datasets['validation'])\n",
        "    if noise_ratio > 0.0:\n",
        "        noise_index = np.random.choice(n_train,\n",
        "                                       size=int(noise_ratio*n_train),\n",
        "                                       replace=False)\n",
        "    else:\n",
        "        noise_index = []\n",
        "\n",
        "    glue_datasets['train'] = glue_datasets['train'].map(flip_label,\n",
        "                                                        with_indices=True,\n",
        "                                                        fn_kwargs={'noise_index':noise_index})\n",
        "    return glue_datasets, noise_index\n",
        "\n",
        "def create_dataloaders(model_name_or_path=\"roberta-large\",\n",
        "                       task=\"mrpc\",\n",
        "                       noise_ratio=0.1,\n",
        "                       batch_size=32):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=\"right\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    sentence1_key, sentence2_key = task_to_keys[task]\n",
        "    def tokenize_function(examples, max_length=128):\n",
        "        # max_length=None => use the model max length (it's actually the default)\n",
        "        if sentence2_key is None:\n",
        "            outputs = tokenizer(examples[sentence1_key], truncation=True, max_length=max_length)\n",
        "        else:\n",
        "            outputs = tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True, max_length=max_length)\n",
        "        return outputs\n",
        "\n",
        "    noisy_datasets, noise_index=load_noisy_dataset_by_task(task=task, noise_ratio=noise_ratio)\n",
        "    if sentence2_key is None:\n",
        "        tokenized_datasets = noisy_datasets.map(\n",
        "            tokenize_function,\n",
        "            batched=True,\n",
        "            remove_columns=[\"idx\", sentence1_key],\n",
        "        )\n",
        "    else:\n",
        "        tokenized_datasets = noisy_datasets.map(\n",
        "            tokenize_function,\n",
        "            batched=True,\n",
        "            remove_columns=[\"idx\", sentence1_key, sentence2_key],\n",
        "        )\n",
        "\n",
        "    # We also rename the 'label' column to 'labels' which is the expected name for labels by the models of the\n",
        "    # transformers library\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "    def collate_fn(examples):\n",
        "        return tokenizer.pad(examples, padding=\"longest\", return_tensors=\"pt\")\n",
        "\n",
        "    train_dataloader = DataLoader(tokenized_datasets[\"train\"],\n",
        "                                  shuffle=True,\n",
        "                                  collate_fn=collate_fn,\n",
        "                                  batch_size=batch_size)\n",
        "    eval_dataloader = DataLoader(tokenized_datasets[\"validation\"],\n",
        "                                 shuffle=False,\n",
        "                                 collate_fn=collate_fn,\n",
        "                                 batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, eval_dataloader, noise_index, tokenized_datasets, collate_fn\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGmvTNh3s4Eg"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import pickle, os\n",
        "import torch\n",
        "import numpy as np\n",
        "### Influence Function Computation by different methods\n",
        "class IFEngine(object):\n",
        "    def __init__(self):\n",
        "        self.time_dict=defaultdict(list)\n",
        "        self.hvp_dict=defaultdict(list)\n",
        "        self.IF_dict=defaultdict(list)\n",
        "\n",
        "    def preprocess_gradients(self, tr_grad_dict, val_grad_dict, noise_index=None):\n",
        "        self.tr_grad_dict = tr_grad_dict\n",
        "        self.val_grad_dict = val_grad_dict\n",
        "        self.noise_index = noise_index\n",
        "\n",
        "        self.n_train = len(self.tr_grad_dict.keys())\n",
        "        self.n_val = len(self.val_grad_dict.keys())\n",
        "        self.compute_val_grad_avg()\n",
        "\n",
        "    def compute_val_grad_avg(self):\n",
        "        # Compute the avg gradient on the validation dataset\n",
        "        self.val_grad_avg_dict={}\n",
        "        for weight_name in self.val_grad_dict[0]:\n",
        "            self.val_grad_avg_dict[weight_name]=torch.zeros(self.val_grad_dict[0][weight_name].shape).to(self.val_grad_dict[0][weight_name].device)\n",
        "            for val_id in self.val_grad_dict:\n",
        "                self.val_grad_avg_dict[weight_name] += self.val_grad_dict[val_id][weight_name] / self.n_val\n",
        "\n",
        "    def compute_hvps(self, lambda_const_param=10, compute_accurate=True):\n",
        "        '''\n",
        "        Compute the influence function score under each method\n",
        "        '''\n",
        "        self.compute_hvp_iterative(lambda_const_param=lambda_const_param)\n",
        "        self.compute_hvp_identity()\n",
        "        self.compute_hvp_proposed(lambda_const_param=lambda_const_param)\n",
        "        self.compute_hvp_LiSSA(lambda_const_param=lambda_const_param)\n",
        "        if compute_accurate:\n",
        "            self.compute_hvp_accurate(lambda_const_param=lambda_const_param)\n",
        "\n",
        "    def compute_hvp_identity(self):\n",
        "        '''\n",
        "        TracIN\n",
        "        '''\n",
        "        start_time = time()\n",
        "        self.hvp_dict['identity'] = self.val_grad_avg_dict.copy()\n",
        "        self.time_dict['identity'] = time()-start_time\n",
        "        print(\"Time taken for Hessian-free: \", self.time_dict['identity'])\n",
        "\n",
        "    def compute_hvp_iterative(self, lambda_const_param=10, n_iteration=30):\n",
        "        '''\n",
        "        Compute the influence funcion score by our method HyperINF\n",
        "        '''\n",
        "\n",
        "        def schulz_inverse_stable(A, damping_factor=0, max_iterations=20, tol=1e-6):\n",
        "            n = A.shape[0]\n",
        "            #I = np.eye(n)\n",
        "            I = torch.eye(n, device=A.device)\n",
        "            A_damped = A + damping_factor * I  # Apply damping\n",
        "\n",
        "            #X = np.eye(n) * 0.00005  # Initial estimate of inverse matrix\n",
        "            X = torch.eye(n, device=A.device) * 0.00005  # Initial estimate of inverse matrix\n",
        "\n",
        "            for _ in range(max_iterations):\n",
        "                #X = X.dot(2 * I - A_damped.dot(X))\n",
        "                X = X @ (2 * I - A_damped @ X)\n",
        "\n",
        "                # # Check for convergence\n",
        "                # if np.linalg.norm(I - A.dot(X)) < tol:\n",
        "                #     break\n",
        "\n",
        "            return X\n",
        "\n",
        "        start_time = time()\n",
        "        hvp_iterative_dict={}\n",
        "\n",
        "        for _, weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
        "            # lambda_const computation = 0.1 x (n * d_l)^(-1) \\sum_{i=1}^{n} ||grad_i^l||_2^2\n",
        "            S=torch.zeros(len(self.tr_grad_dict.keys())).to(self.val_grad_avg_dict[weight_name].device)\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "                tmp_grad = self.tr_grad_dict[tr_id][weight_name]\n",
        "                S[tr_id]=torch.mean(tmp_grad**2)\n",
        "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
        "\n",
        "            # iterative hvp computation\n",
        "            # G_l: same shape of self.tr_grad_dict[0][weight_name].T @ self.tr_grad_dict[0][weight_name]\n",
        "            G_l = torch.zeros((self.tr_grad_dict[0][weight_name].T @ self.tr_grad_dict[0][weight_name]).shape).to(self.val_grad_avg_dict[weight_name].device)\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device) # (grad_i^l)^T\n",
        "                G_l += tmp_grad.T @ tmp_grad / self.n_train\n",
        "\n",
        "            G_l = G_l + lambda_const * torch.eye(G_l.shape[0], device=G_l.device)\n",
        "           # G_l = G_l.cpu().detach().numpy()\n",
        "            G_l_inv = schulz_inverse_stable(G_l, damping_factor=0.001, max_iterations=n_iteration, tol=1e-6)\n",
        "\n",
        "            hvp_iterative_dict[weight_name] = torch.tensor(self.val_grad_avg_dict[weight_name] @ G_l_inv)\n",
        "            #print(hvp_iterative_dict[weight_name])\n",
        "        self.hvp_dict['iterative'] = hvp_iterative_dict\n",
        "        self.time_dict['iterative'] = time()-start_time\n",
        "        print(\"Time taken for HyperINF: \", self.time_dict['iterative'])\n",
        "\n",
        "\n",
        "\n",
        "    def compute_hvp_proposed(self, lambda_const_param=10):\n",
        "        '''\n",
        "        DataInf method\n",
        "        '''\n",
        "        start_time = time()\n",
        "        hvp_proposed_dict={}\n",
        "\n",
        "        for _ , weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
        "            # lambda_const computation = 0.1 x (n * d_l)^(-1) \\sum_{i=1}^{n} ||grad_i^l||_2^2\n",
        "            S=torch.zeros(len(self.tr_grad_dict.keys())).to(self.val_grad_avg_dict[weight_name].device)\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device)\n",
        "                S[tr_id]=torch.mean(tmp_grad**2)\n",
        "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
        "\n",
        "            # hvp computation\n",
        "            hvp=torch.zeros(self.val_grad_avg_dict[weight_name].shape).to(self.val_grad_avg_dict[weight_name].device)\n",
        "            for tr_id in self.tr_grad_dict: # i\n",
        "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device) # grad_i^l\n",
        "                # L_(l,i) / (lambda + ||grad_i^l||_2^2) in Eqn. (5)\n",
        "                C_tmp = torch.sum(self.val_grad_avg_dict[weight_name] * tmp_grad) / (lambda_const + torch.sum(tmp_grad**2)).to(self.val_grad_avg_dict[weight_name].device)\n",
        "                # (v_l^T - C_tmp * (grad_i^l)^T ) / (n * lambda) in Eqn. (5)\n",
        "                hvp += (self.val_grad_avg_dict[weight_name] - C_tmp*tmp_grad) / (self.n_train*lambda_const)\n",
        "            hvp_proposed_dict[weight_name] = hvp\n",
        "        self.hvp_dict['proposed'] = hvp_proposed_dict\n",
        "        self.time_dict['proposed'] = time()-start_time\n",
        "        print(\"Time taken for Datainf: \", self.time_dict['proposed'])\n",
        "\n",
        "    def compute_hvp_accurate(self, lambda_const_param=10):\n",
        "        start_time = time()\n",
        "        hvp_accurate_dict={}\n",
        "        for _ , weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
        "\n",
        "            # lambda_const computation\n",
        "            S=torch.zeros(len(self.tr_grad_dict.keys()))\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "                tmp_grad = self.tr_grad_dict[tr_id][weight_name]\n",
        "                S[tr_id]=torch.mean(tmp_grad**2)\n",
        "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
        "\n",
        "            # hvp computation (eigenvalue decomposition)\n",
        "            AAt_matrix = torch.zeros(torch.outer(self.tr_grad_dict[0][weight_name].reshape(-1),\n",
        "                                                 self.tr_grad_dict[0][weight_name].reshape(-1)).shape)\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "\n",
        "                tmp_mat = torch.outer(self.tr_grad_dict[tr_id][weight_name].reshape(-1),\n",
        "                                      self.tr_grad_dict[tr_id][weight_name].reshape(-1))\n",
        "                AAt_matrix += tmp_mat\n",
        "\n",
        "\n",
        "            L, V = torch.linalg.eig(AAt_matrix)\n",
        "            L, V = L.float(), V.float()\n",
        "            hvp = self.val_grad_avg_dict[weight_name].reshape(-1) @ V\n",
        "            hvp = (hvp / (lambda_const + L/ self.n_train)) @ V.T\n",
        "\n",
        "            hvp_accurate_dict[weight_name] = hvp.reshape(len(self.tr_grad_dict[0][weight_name]), -1)\n",
        "            del tmp_mat, AAt_matrix, V # to save memory\n",
        "        self.hvp_dict['accurate'] = hvp_accurate_dict\n",
        "        self.time_dict['accurate'] = time()-start_time\n",
        "        print(\"Time taken for Accurate: \", self.time_dict['accurate'])\n",
        "\n",
        "    def compute_hvp_LiSSA(self, lambda_const_param=10, n_iteration=10, alpha_const=1.):\n",
        "        '''\n",
        "        LiSSA method\n",
        "        '''\n",
        "        start_time = time()\n",
        "        hvp_LiSSA_dict={}\n",
        "\n",
        "        for _, weight_name in enumerate(tqdm(self.val_grad_avg_dict)):\n",
        "            # lambda_const computation\n",
        "            S=torch.zeros(len(self.tr_grad_dict.keys())).to(self.val_grad_avg_dict[weight_name].device)\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device)\n",
        "                S[tr_id]=torch.mean(tmp_grad**2)\n",
        "            lambda_const = torch.mean(S) / lambda_const_param # layer-wise lambda\n",
        "\n",
        "            # hvp computation\n",
        "            running_hvp=self.val_grad_avg_dict[weight_name]\n",
        "            hvp_tmp=torch.zeros(self.val_grad_avg_dict[weight_name].shape).to(self.val_grad_avg_dict[weight_name].device)\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "                tmp_grad = self.tr_grad_dict[tr_id][weight_name].to(self.val_grad_avg_dict[weight_name].device)\n",
        "                hvp_tmp += (torch.sum(tmp_grad*running_hvp)*tmp_grad - lambda_const*running_hvp) / self.n_train\n",
        "\n",
        "            for _ in range(n_iteration):\n",
        "                running_hvp = self.val_grad_avg_dict[weight_name] + running_hvp - alpha_const*hvp_tmp\n",
        "            hvp_LiSSA_dict[weight_name] = running_hvp\n",
        "\n",
        "        self.hvp_dict['LiSSA'] = hvp_LiSSA_dict\n",
        "        self.time_dict['LiSSA'] = time()-start_time\n",
        "        print(\"Time taken for LiSSA: \", self.time_dict['LiSSA'])\n",
        "\n",
        "    def compute_IF(self):\n",
        "        for method_name in self.hvp_dict:\n",
        "            if_tmp_dict = {}\n",
        "            for tr_id in self.tr_grad_dict:\n",
        "                if_tmp_value = 0\n",
        "                for weight_name in self.val_grad_avg_dict:\n",
        "                    if_tmp_value += torch.sum(self.hvp_dict[method_name][weight_name]*self.tr_grad_dict[tr_id][weight_name])\n",
        "                if_tmp_dict[tr_id]= -if_tmp_value.cpu()\n",
        "               # print(-if_tmp_value)\n",
        "\n",
        "            self.IF_dict[method_name] = pd.Series(if_tmp_dict, dtype=float).to_numpy()\n",
        "\n",
        "    def save_result(self, noise_index, run_id=0):\n",
        "        results={}\n",
        "        results['runtime']=self.time_dict\n",
        "        results['noise_index']=noise_index\n",
        "        results['influence']=self.IF_dict\n",
        "\n",
        "        with open(f\"./results_{run_id}.pkl\",'wb') as file:\n",
        "            pickle.dump(results, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57K8aADbs4Eh"
      },
      "outputs": [],
      "source": [
        "## LoRA model\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    # BitsAndBytesConfig,\n",
        "    # LlamaForCausalLM,\n",
        "    # LlamaTokenizer\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model\n",
        ")\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "\n",
        "class LORAEngine(object):\n",
        "    def __init__(self,\n",
        "                model_name_or_path=\"roberta-large\",\n",
        "                target_modules=[\"value\"],\n",
        "                train_dataloader=None,\n",
        "                eval_dataloader=None,\n",
        "                device=\"cuda\",\n",
        "                num_epochs=10,\n",
        "                lr=3e-4,\n",
        "                lora=False,\n",
        "                low_rank=2,\n",
        "                task=\"mrpc\"):\n",
        "        self.model_name_or_path=model_name_or_path\n",
        "        self.target_modules=target_modules\n",
        "        self.train_dataloader=train_dataloader\n",
        "        self.eval_dataloader=eval_dataloader\n",
        "        self.device=device\n",
        "        self.num_epochs=num_epochs\n",
        "        self.lr=lr\n",
        "        self.task=task\n",
        "        self.lora=lora\n",
        "        self.low_rank=low_rank\n",
        "\n",
        "    def build_LORA_model(self):\n",
        "        '''\n",
        "        This function fine-tunes a model for classification tasks.\n",
        "        For text generation tasks, please see `notebooks/Influential_Data_Identification-Llama2-Math.ipynb`.\n",
        "        '''\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name_or_path,\n",
        "                                                                        return_dict=True)\n",
        "        self.model.config.use_cache = False\n",
        "        self.model.config.pad_token_id = self.model.config.eos_token_id\n",
        "\n",
        "        if self.lora:\n",
        "            peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
        "                                    inference_mode=False,\n",
        "                                    target_modules=self.target_modules,\n",
        "                                    r=self.low_rank,\n",
        "                                    lora_alpha=self.low_rank * 2,\n",
        "                                    use_rslora=True,\n",
        "                                    #lora_dropout=0.05\n",
        "                                    )\n",
        "            self.model = get_peft_model(self.model, peft_config)\n",
        "            self.model.print_trainable_parameters()\n",
        "\n",
        "    def train_LORA_model(self):\n",
        "        '''\n",
        "        This function fine-tunes a model for GLUE classification tasks.\n",
        "        For text generation tasks, please see `notebooks/Influential_Data_Identification-Llama2-Math.ipynb`.\n",
        "        '''\n",
        "        metric = evaluate.load(\"glue\", self.task)\n",
        "        optimizer = AdamW(params=self.model.parameters(), lr=self.lr)\n",
        "\n",
        "        # Instantiate scheduler\n",
        "        lr_scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=0.06*(len(self.train_dataloader)*self.num_epochs),\n",
        "            num_training_steps=(len(self.train_dataloader)*self.num_epochs),\n",
        "        )\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.model.train()\n",
        "            for step, batch in enumerate(tqdm(self.train_dataloader)):\n",
        "                batch.to(self.device)\n",
        "                outputs = self.model(**batch)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            self.model.eval()\n",
        "            for step, batch in enumerate(tqdm(self.eval_dataloader)):\n",
        "                batch.to(self.device)\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.model(**batch)\n",
        "                predictions = outputs.logits.argmax(dim=-1)\n",
        "                predictions, references = predictions, batch[\"labels\"]\n",
        "                metric.add_batch(\n",
        "                    predictions=predictions,\n",
        "                    references=references,\n",
        "                )\n",
        "\n",
        "            eval_metric = metric.compute()\n",
        "            print(f\"Epoch {(epoch+1)}:\", eval_metric)\n",
        "\n",
        "\n",
        "    def compute_gradient(self, tokenized_datasets, collate_fn):\n",
        "        train_dataloader_stochastic = DataLoader(tokenized_datasets[\"train\"],\n",
        "                                                  shuffle=False,\n",
        "                                                  collate_fn=collate_fn,\n",
        "                                                  batch_size=1)\n",
        "\n",
        "        val_dataloader_stochastic = DataLoader(tokenized_datasets[\"validation\"],\n",
        "                                                  shuffle=False,\n",
        "                                                  collate_fn=collate_fn,\n",
        "                                                  batch_size=1)\n",
        "        # Compute the gradient\n",
        "        self.model.eval()\n",
        "        tr_grad_dict = {}\n",
        "        for step, batch in enumerate(tqdm(train_dataloader_stochastic)):\n",
        "            self.model.zero_grad() # zeroing out gradient\n",
        "            batch.to(self.device)\n",
        "            outputs = self.model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            grad_dict={}\n",
        "\n",
        "            if self.lora:\n",
        "                for k, v in self.model.named_parameters():\n",
        "                    if 'lora_A' in k:\n",
        "                        grad_dict[k]=v.grad.cpu()\n",
        "                    elif 'lora_B' in k:\n",
        "                        # first index of shape indicates low-rank\n",
        "                        grad_dict[k]=v.grad.cpu().T\n",
        "                    elif 'modules_to_save.default.out_proj.weight' in k:\n",
        "                        grad_dict[k]=v.grad.cpu()\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "\n",
        "            tr_grad_dict[step]=grad_dict\n",
        "            del grad_dict\n",
        "\n",
        "        val_grad_dict = {}\n",
        "        for step, batch in enumerate(tqdm(val_dataloader_stochastic)):\n",
        "            self.model.zero_grad() # zeroing out gradient\n",
        "            batch.to(self.device)\n",
        "            outputs = self.model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            grad_dict={}\n",
        "\n",
        "            if self.lora:\n",
        "                for k, v in self.model.named_parameters():\n",
        "                    if 'lora_A' in k:\n",
        "                        grad_dict[k]=v.grad.cpu()\n",
        "                    elif 'lora_B' in k:\n",
        "                        # first index of shape indicates low-rank\n",
        "                        grad_dict[k]=v.grad.cpu().T\n",
        "                    elif 'modules_to_save.default.out_proj.weight' in k:\n",
        "                        grad_dict[k]=v.grad.cpu()\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "            val_grad_dict[step]=grad_dict\n",
        "            del grad_dict\n",
        "\n",
        "        return tr_grad_dict, val_grad_dict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xksw53hWs4Eh"
      },
      "source": [
        "## 2. Mislabeled Data Detection on MRPC (Roberta-large, LoRA rank=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrRm8ywbs4Ei",
        "outputId": "61796e5e-5c26-4e51-9ecb-998be2902370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 3668/3668 [00:00<00:00, 9103.93 examples/s] \n",
            "Map: 100%|██████████| 3668/3668 [00:00<00:00, 8545.07 examples/s]\n",
            "Map: 100%|██████████| 408/408 [00:00<00:00, 9437.31 examples/s]\n",
            "Map: 100%|██████████| 1725/1725 [00:00<00:00, 11938.01 examples/s]\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 2,624,514 || all params: 357,986,308 || trainable%: 0.7331325085204097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/115 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100%|██████████| 115/115 [00:25<00:00,  4.44it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.63it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.63it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: {'accuracy': 0.7009803921568627, 'f1': 0.8195266272189349}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.61it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: {'accuracy': 0.7009803921568627, 'f1': 0.8200589970501475}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.60it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: {'accuracy': 0.7132352941176471, 'f1': 0.8197226502311248}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.62it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: {'accuracy': 0.7377450980392157, 'f1': 0.834108527131783}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.66it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: {'accuracy': 0.7598039215686274, 'f1': 0.842948717948718}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.64it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: {'accuracy': 0.7622549019607843, 'f1': 0.8452950558213717}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.64it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: {'accuracy': 0.7990196078431373, 'f1': 0.8651315789473685}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.61it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: {'accuracy': 0.8063725490196079, 'f1': 0.8672268907563025}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.64it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: {'accuracy': 0.8063725490196079, 'f1': 0.8719611021069692}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.61it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: {'accuracy': 0.8259803921568627, 'f1': 0.8706739526411658}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.64it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: {'accuracy': 0.8186274509803921, 'f1': 0.8737201365187713}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.65it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: {'accuracy': 0.821078431372549, 'f1': 0.8756388415672913}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 115/115 [00:24<00:00,  4.62it/s]\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: {'accuracy': 0.8235294117647058, 'f1': 0.8745644599303136}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3668/3668 [05:30<00:00, 11.08it/s]  \n",
            "100%|██████████| 408/408 [00:27<00:00, 14.87it/s]\n",
            "100%|██████████| 97/97 [00:28<00:00,  3.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken for HyperINF:  28.372716426849365\n",
            "Time taken for Hessian-free:  0.0003275871276855469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97/97 [00:50<00:00,  1.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken for Datainf:  50.50327920913696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97/97 [00:36<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken for LiSSA:  36.56831240653992\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "## set seed for production\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "## model's settings\n",
        "model_name_or_path=\"roberta-large\"\n",
        "task = \"mrpc\"\n",
        "noise_ratio=0.2\n",
        "batch_size=32\n",
        "rank = 16\n",
        "target_modules=[\"value\",\"query\"]\n",
        "device=\"cuda\"\n",
        "num_epochs=15\n",
        "lr= 3e-5\n",
        "\n",
        "## load data\n",
        "dataloader_outputs = create_dataloaders(model_name_or_path=model_name_or_path,\n",
        "                                            task=task,\n",
        "                                            noise_ratio=noise_ratio,\n",
        "                                            batch_size=batch_size)\n",
        "train_dataloader, eval_dataloader, noise_index, tokenized_datasets, collate_fn=dataloader_outputs\n",
        "\n",
        "## LoRA Model\n",
        "lora_engine = LORAEngine(model_name_or_path=model_name_or_path,\n",
        "                            target_modules=target_modules,\n",
        "                            train_dataloader=train_dataloader,\n",
        "                            eval_dataloader=eval_dataloader,\n",
        "                            device=device,\n",
        "                            num_epochs=num_epochs,\n",
        "                            lr=lr,\n",
        "                            lora=True,\n",
        "                            low_rank=rank,\n",
        "                            task=task)\n",
        "\n",
        "\n",
        "lora_engine.build_LORA_model()\n",
        "lora_engine.train_LORA_model()\n",
        "\n",
        "## get the train_grad and val_grad from fine-tuned model\n",
        "tr_grad_dict, val_grad_dict = lora_engine.compute_gradient(tokenized_datasets, collate_fn)\n",
        "## to cuda\n",
        "for key in tr_grad_dict:\n",
        "    for kk in tr_grad_dict[key]:\n",
        "        tr_grad_dict[key][kk] = tr_grad_dict[key][kk].to(device)\n",
        "\n",
        "for key in val_grad_dict:\n",
        "    for kk in val_grad_dict[key]:\n",
        "        val_grad_dict[key][kk] = val_grad_dict[key][kk].to(device)\n",
        "\n",
        "\n",
        "## compute influence function\n",
        "influence_engine = IFEngine()\n",
        "influence_engine.preprocess_gradients(tr_grad_dict, val_grad_dict, noise_index)\n",
        "\n",
        "influence_engine.compute_hvps(compute_accurate=False)\n",
        "influence_engine.compute_IF()\n",
        "\n",
        "n_train=influence_engine.n_train\n",
        "true_label=np.zeros(n_train)\n",
        "true_label[noise_index]=1\n",
        "\n",
        "method_dict={\n",
        "    'identity': 'TracIN',\n",
        "            'proposed': 'DataInf',\n",
        "            'iterative': 'HyperINF',\n",
        "            'LiSSA': 'LiSSA'\n",
        "            }\n",
        "\n",
        "## plot the detection-ratio\n",
        "plt.figure(figsize=(5,4))\n",
        "\n",
        "for method in influence_engine.IF_dict:\n",
        "    detection_rate_list=[]\n",
        "    low_quality_to_high_quality=np.argsort(influence_engine.IF_dict[method])[::-1]\n",
        "    for ind in range(1, len(low_quality_to_high_quality)+1):\n",
        "        # detected_samples: the samples that are detected as noise\n",
        "        detected_samples = set(low_quality_to_high_quality[:ind]).intersection(noise_index)\n",
        "        detection_rate = 100*len(detected_samples)/len(noise_index)\n",
        "        detection_rate_list.append(detection_rate)\n",
        "\n",
        "\n",
        "    plt.plot(100*np.arange(len(low_quality_to_high_quality))/n_train,\n",
        "            detection_rate_list,\n",
        "            #marker='s',\n",
        "            label=method_dict[method])\n",
        "\n",
        "\n",
        "## plot random detection rate from (0,0) to (100,100)\n",
        "plt.plot([0, 100], [0, 100], linestyle='--', color='black', label='Random')\n",
        "## plot perfect detection rate from (0,0) to (20,100), (20,100) to (100,100)\n",
        "plt.plot([0, 20], [0, 100], linestyle='--', color='red', label='Perfect')\n",
        "plt.plot([20, 100], [100, 100], linestyle='--', color='red')\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZBmDpBUs4Ei"
      },
      "source": [
        "## 3. Running Time Comparison\n",
        "- Gaussian Elimination\n",
        "- Fast Faussian Elimination (torch.inverse)\n",
        "- GMRES approximation with Scipy and torch adaptation\n",
        "- the Schulz's method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UVcuPlyI2dlV"
      },
      "outputs": [],
      "source": [
        "### Updated torch linalg\n",
        "### adapted from https://github.com/devzhk/Pytorch-linalg\n",
        "import torch\n",
        "from functools import partial\n",
        "import warnings\n",
        "\n",
        "def fxn():\n",
        "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    fxn()\n",
        "\n",
        "def _check_nan(vec, msg):\n",
        "    if torch.isnan(vec).any():\n",
        "        raise ValueError(msg)\n",
        "\n",
        "\n",
        "def _safe_normalize(x, threshold=None):\n",
        "    norm = torch.norm(x)\n",
        "    if threshold is None:\n",
        "        threshold = torch.finfo(norm.dtype).eps\n",
        "    normalized_x = x / norm if norm > threshold else torch.zeros_like(x)\n",
        "    return normalized_x, norm\n",
        "\n",
        "\n",
        "def Mvp(A, vec):\n",
        "    return A @ vec\n",
        "\n",
        "\n",
        "def arnoldi(vec,    # Matrix vector product\n",
        "            V,      # List of existing basis\n",
        "            H,      # H matrix\n",
        "            j):     # number of basis\n",
        "    '''\n",
        "    Arnoldi iteration to find the j th l2-orthonormal vector\n",
        "    compute the j-1 th column of Hessenberg matrix\n",
        "    '''\n",
        "    _check_nan(vec, 'Matrix vector product is Nan')\n",
        "\n",
        "    for i in range(j):\n",
        "        H[i, j - 1] = torch.dot(vec, V[i])\n",
        "        vec = vec - H[i, j-1] * V[i]\n",
        "    new_v, vnorm = _safe_normalize(vec)\n",
        "    H[j, j - 1] = vnorm\n",
        "    return new_v\n",
        "\n",
        "\n",
        "def cal_rotation(a, b):\n",
        "    '''\n",
        "    Args:\n",
        "        a: element h in position j\n",
        "        b: element h in position j+1\n",
        "    Returns:\n",
        "        cosine = a / \\sqrt{a^2 + b^2}\n",
        "        sine = - b / \\sqrt{a^2 + b^2}\n",
        "    '''\n",
        "    c = torch.sqrt(a * a + b * b)\n",
        "    return a / c, - b / c\n",
        "\n",
        "\n",
        "def apply_given_rotation(H, cs, ss, j):\n",
        "    '''\n",
        "    Apply givens rotation to H columns\n",
        "    :param H:\n",
        "    :param cs:\n",
        "    :param ss:\n",
        "    :param j:\n",
        "    :return:\n",
        "    '''\n",
        "    # apply previous rotation to the 0->j-1 columns\n",
        "    for i in range(j):\n",
        "        tmp = cs[i] * H[i, j] - ss[i] * H[i + 1, j]\n",
        "        H[i + 1, j] = cs[i] * H[i+1, j] + ss[i] * H[i, j]\n",
        "        H[i, j] = tmp\n",
        "    cs[j], ss[j] = cal_rotation(H[j, j], H[j + 1, j])\n",
        "    H[j, j] = cs[j] * H[j, j] - ss[j] * H[j + 1, j]\n",
        "    H[j + 1, j] = 0\n",
        "    return H, cs, ss\n",
        "\n",
        "\n",
        "'''\n",
        "    GMRES solver for solving Ax=b.\n",
        "    Reference: https://web.stanford.edu/class/cme324/saad-schultz.pdf\n",
        "'''\n",
        "\n",
        "def GMRES(A,                # Linear operator, matrix or function\n",
        "          b,                # RHS of the linear system in which the first half has the same shape as grad_gx, the second half has the same shape as grad_fy\n",
        "          x0=None,          # initial guess, tuple has the same shape as b\n",
        "          max_iter=None,    # maximum number of GMRES iterations\n",
        "          tol=1e-6,         # relative tolerance\n",
        "          atol=1e-6,        # absolute tolerance\n",
        "          track=False):     # If True, track the residual error of each iteration\n",
        "    '''\n",
        "    Return:\n",
        "        sol: solution\n",
        "        (j, err_history):\n",
        "            j is the number of iterations used to achieve the target accuracy;\n",
        "            err_history is a list of relative residual error at each iteration if track=True, empty list otherwise.\n",
        "    '''\n",
        "    if isinstance(A, torch.Tensor):\n",
        "        Avp = partial(Mvp, A)\n",
        "    elif hasattr(A, '__call__'):\n",
        "        Avp = A\n",
        "    else:\n",
        "        raise ValueError('A must be a function or matrix')\n",
        "\n",
        "    bnorm = torch.norm(b)\n",
        "\n",
        "    if max_iter == 0 or bnorm < 1e-8:\n",
        "        return b\n",
        "\n",
        "    if max_iter is None:\n",
        "        max_iter = b.shape[0]\n",
        "\n",
        "    if x0 is None:\n",
        "        x0 = torch.zeros_like(b)\n",
        "        r0 = b\n",
        "    else:\n",
        "        r0 = b - Avp(x0)\n",
        "\n",
        "    new_v, rnorm = _safe_normalize(r0)\n",
        "    # initial guess residual\n",
        "    beta = torch.zeros(max_iter + 1, device=b.device)\n",
        "    beta[0] = rnorm\n",
        "    err_history = []\n",
        "    if track:\n",
        "        err_history.append((rnorm / bnorm).item())\n",
        "\n",
        "    V = []\n",
        "    V.append(new_v)\n",
        "    H = torch.zeros((max_iter + 1, max_iter + 1), device=b.device)\n",
        "    cs = torch.zeros(max_iter, device=b.device)  # cosine values at each step\n",
        "    ss = torch.zeros(max_iter, device=b.device)  # sine values at each step\n",
        "\n",
        "    for j in range(max_iter):\n",
        "        p = Avp(V[j])\n",
        "        new_v = arnoldi(p, V, H, j + 1)  # Arnoldi iteration to get the j+1 th basis\n",
        "        V.append(new_v)\n",
        "\n",
        "        H, cs, ss = apply_given_rotation(H, cs, ss, j)\n",
        "        beta[j + 1] = ss[j] * beta[j]\n",
        "        beta[j] = cs[j] * beta[j]\n",
        "        residual = torch.abs(beta[j + 1])\n",
        "        if track:\n",
        "            err_history.append((residual / bnorm).item())\n",
        "        if residual < tol * bnorm or residual < atol:\n",
        "            break\n",
        "    y, _ = torch.triangular_solve(beta[0:j + 1].unsqueeze(-1), H[0:j + 1, 0:j + 1])  # j x j\n",
        "    V = torch.stack(V[:-1], dim=0)\n",
        "    sol = x0 + V.T @ y.squeeze(-1)\n",
        "    return sol, (j, err_history)\n",
        "\n",
        "\n",
        "'''\n",
        "  Conjugate Gradient algorithm for solving Ax=b.\n",
        "  Reference: https://en.wikipedia.org/wiki/Conjugate_gradient_method\n",
        "'''\n",
        "\n",
        "def CG(A,                   # linear operator\n",
        "       b,                   # RHS of the linear system\n",
        "       x0=None,             # initial guess\n",
        "       max_iter=None,       # maximum number of iterations\n",
        "       tol=1e-5,            # relative tolerance\n",
        "       atol=1e-6,           # absolute tolerance\n",
        "       track=False,         # if True, track the residual error of each iteration\n",
        "       ):\n",
        "    '''\n",
        "    Return:\n",
        "        sol: solution\n",
        "        (j, err_history):\n",
        "            j is the number of iterations used to achieve the target accuracy;\n",
        "            err_history is a list of relative residual error at each iteration if track=True, empty list otherwise.\n",
        "    '''\n",
        "    if isinstance(A, torch.Tensor):\n",
        "        Avp = partial(Mvp, A)\n",
        "    elif hasattr(A, '__call__'):\n",
        "        Avp = A\n",
        "    else:\n",
        "        raise ValueError('A must be a function or squared matrix')\n",
        "\n",
        "    if max_iter is None:\n",
        "        max_iter = b.shape[0]\n",
        "    if x0 is None:\n",
        "        x = torch.zeros_like(b)\n",
        "        r = b.detach().clone()\n",
        "    else:\n",
        "        Av = Avp(x0)\n",
        "        r = b.detach().clone() - Av\n",
        "        x = x0\n",
        "\n",
        "    p = r.clone()\n",
        "    rdotr = torch.dot(r, r)\n",
        "    err_history = []\n",
        "    if track:\n",
        "        err_history.append(rdotr.item())\n",
        "\n",
        "    residual_tol = max(tol * tol * torch.dot(b, b), atol * atol)\n",
        "    if rdotr < residual_tol:\n",
        "        return x, 0\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        Ap = Avp(p)\n",
        "\n",
        "        alpha = rdotr / torch.dot(p, Ap)\n",
        "        x.add_(alpha * p)\n",
        "        r.add_(-alpha * Ap)\n",
        "        new_rdotr = torch.dot(r, r)\n",
        "        beta = new_rdotr / rdotr\n",
        "        p = r + beta * p\n",
        "        rdotr = new_rdotr\n",
        "        if track:\n",
        "            err_history.append(rdotr.item())\n",
        "        if rdotr < residual_tol:\n",
        "            break\n",
        "    return x, (i + 1, err_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Xf27cF6XoZ",
        "outputId": "3e0a3843-05a3-48bf-9b08-f75db5fb01fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inverse of A:\n",
            "torch.Size([3, 3])\n",
            "Product of A and A_inv (should be close to identity):\n",
            "tensor([[ 1.0000e+00,  0.0000e+00, -7.4506e-09],\n",
            "        [-2.2352e-08,  1.0000e+00, -2.9802e-08],\n",
            "        [-7.4506e-09,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
            "tensor([[1.0000e+00, 0.0000e+00, 7.4506e-09],\n",
            "        [1.1176e-08, 1.0000e+00, 0.0000e+00],\n",
            "        [7.4506e-09, 0.0000e+00, 1.0000e+00]], device='cuda:0')\n",
            "tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 9.3132e-09,  1.0000e+00, -2.9802e-08],\n",
            "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_123932/503960675.py:149: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
            "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
            "X = torch.triangular_solve(B, A).solution\n",
            "should be replaced with\n",
            "X = torch.linalg.solve_triangular(A, B). (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035891/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2192.)\n",
            "  y, _ = torch.triangular_solve(beta[0:j + 1].unsqueeze(-1), H[0:j + 1, 0:j + 1])  # j x j\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse.linalg import gmres\n",
        "\n",
        "def scipy_gmres_inverse(A, tol=1e-6, maxiter=None):\n",
        "    \"\"\"\n",
        "    Compute the inverse of a matrix using the GMRES method.\n",
        "\n",
        "    Parameters:\n",
        "    A : numpy.ndarray\n",
        "        A square matrix to invert.\n",
        "    tol : float\n",
        "        Tolerance for convergence (default 1e-8).\n",
        "    maxiter : int or None\n",
        "        Maximum number of iterations (default None, i.e., no limit).\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray\n",
        "        The inverse of the matrix A.\n",
        "    \"\"\"\n",
        "    n = A.shape[0]\n",
        "    A_inv = np.zeros_like(A, dtype=np.float64)\n",
        "    identity = np.eye(n)\n",
        "\n",
        "    for i in range(n):\n",
        "        b = identity[:, i]\n",
        "        x, _ = gmres(A, b, atol=tol, maxiter=maxiter)\n",
        "        A_inv[:, i] = x\n",
        "    return A_inv\n",
        "\n",
        "def pytorch_gmres_inverse(A, tol=1e-6, maxiter=None):\n",
        "    \"\"\"\n",
        "    Compute the inverse of a matrix using the GMRES method (pytorch).\n",
        "    \"\"\"\n",
        "    n = A.shape[0]\n",
        "    A_inv = torch.zeros_like(A).to(A.device)\n",
        "    identity = torch.eye(n).to(A.device)\n",
        "\n",
        "    for i in range(n):\n",
        "        b = identity[:, i]\n",
        "        x, _ = GMRES(A, b, atol=tol, max_iter=maxiter)\n",
        "        A_inv[:, i] = x\n",
        "\n",
        "    return A_inv\n",
        "\n",
        "def conjugate_gradient_inverse(A, tol=1e-6, maxiter=None):\n",
        "    \"\"\"\n",
        "    Compute the inverse of a matrix using the gradient conjugate method.\n",
        "    \"\"\"\n",
        "    n = A.shape[0]\n",
        "    A_inv = torch.zeros_like(A).to(A.device)\n",
        "    identity = torch.eye(n).to(A.device)\n",
        "\n",
        "    for i in range(n):\n",
        "        b = identity[:, i]\n",
        "        x, _ = CG(A, b, atol=tol, max_iter=maxiter)\n",
        "        A_inv[:, i] = x\n",
        "\n",
        "    return A_inv\n",
        "\n",
        "\n",
        "def gaussian_elimination_inverse(A):\n",
        "    \"\"\"\n",
        "    Compute the inverse of a matrix using Gaussian elimination.\n",
        "\n",
        "    Parameters:\n",
        "    A : torch.Tensor\n",
        "        A square matrix to invert.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor\n",
        "        The inverse of the matrix A, if it exists. Otherwise, raises an error.\n",
        "    \"\"\"\n",
        "    # Ensure A is a float tensor for precision and avoid integer division issues\n",
        "    A = A.float()\n",
        "\n",
        "    n = A.shape[0]\n",
        "    assert A.shape[1] == n, \"Matrix must be square\"\n",
        "\n",
        "    # Create an augmented matrix with the identity matrix on the right\n",
        "    augmented = torch.cat((A, torch.eye(n).to(A.device)), dim=1).to(A.device)\n",
        "\n",
        "    # Gaussian elimination\n",
        "    for i in range(n):\n",
        "        # Find the pivot element and swap rows if necessary\n",
        "        max_row = torch.argmax(torch.abs(augmented[i:, i])) + i\n",
        "        if augmented[max_row, i] == 0:\n",
        "            raise ValueError(\"Matrix is singular and cannot be inverted.\")\n",
        "\n",
        "        if max_row != i:\n",
        "            # Swap rows\n",
        "            augmented[[i, max_row]] = augmented[[max_row, i]]\n",
        "\n",
        "        # Normalize the pivot row\n",
        "        pivot = augmented[i, i]\n",
        "        augmented[i] = augmented[i] / pivot\n",
        "\n",
        "        # Eliminate all other entries in the current column\n",
        "        for j in range(n):\n",
        "            if j != i:\n",
        "                factor = augmented[j, i]\n",
        "                augmented[j] -= factor * augmented[i]\n",
        "\n",
        "    # The right half of the augmented matrix is now the inverse of the original matrix\n",
        "    A_inv = augmented[:, n:]\n",
        "    return A_inv\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # A = np.array([[4, 1, 0], [1, 4, 1], [0, 1, 4]])\n",
        "    A = torch.tensor([[4, 1, 0], [1, 4, 1], [0, 1, 4]], dtype=torch.float32).to('cuda')\n",
        "    A_inv_gmres = pytorch_gmres_inverse(A)\n",
        "    A_inv_cg = conjugate_gradient_inverse(A)\n",
        "    A_inv_gaussian = gaussian_elimination_inverse(A)\n",
        "    print(\"Inverse of A:\")\n",
        "    print(A_inv_gmres.shape)\n",
        "    print(\"Product of A and A_inv (should be close to identity):\")\n",
        "    print(torch.matmul(A, A_inv_gmres))\n",
        "    print(torch.matmul(A, A_inv_cg))\n",
        "    print(torch.matmul(A, A_inv_gaussian))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LEmQW63s4Ej",
        "outputId": "ba3a34a8-e709-4098-a5e8-b9123dc908b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE:  cuda\n",
            "Dimension:  16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gaussian Elimination Time:  0.00794219970703125\n",
            "GMRES(scipy) Time:  0.02333521842956543\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.012070178985595703\n",
            "GMRES(torch) Time:  0.04490160942077637\n",
            "Schulz Time:  0.004580497741699219\n",
            "(torch.inverse) Error:  2.6009487896772045e-11\n",
            "GMRES (scipy) Error:  1.8275714380897133e-10\n",
            "Schulz Error:  4.8822772669154804e-11\n",
            "GMRES (torch) Error:  1.8345793932894593e-10\n",
            "Gaussian Elimination Time:  0.007309436798095703\n",
            "GMRES(scipy) Time:  0.0051767826080322266\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.0004572868347167969\n",
            "GMRES(torch) Time:  0.05521249771118164\n",
            "Schulz Time:  0.0007293224334716797\n",
            "(torch.inverse) Error:  3.155670356136397e-11\n",
            "GMRES (scipy) Error:  4.4291992578860617e-10\n",
            "Schulz Error:  3.629238563007675e-11\n",
            "GMRES (torch) Error:  1.0623186881275614e-10\n",
            "Gaussian Elimination Time:  0.0071222782135009766\n",
            "GMRES(scipy) Time:  0.004746198654174805\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.0005347728729248047\n",
            "GMRES(torch) Time:  0.05487060546875\n",
            "Schulz Time:  0.0007765293121337891\n",
            "(torch.inverse) Error:  3.320723180877394e-11\n",
            "GMRES (scipy) Error:  4.259356320717859e-10\n",
            "Schulz Error:  4.384397698231624e-11\n",
            "GMRES (torch) Error:  8.656223258185491e-11\n",
            "====== Summary on Dim 16 ======\n",
            "-->> Time Cost (s)\n",
            "Gaussian Elimination:  0.0074579715728759766 ± 0.0003508226032032889\n",
            "GMRES (scipy):  0.011086066563924154 ± 0.008663241953063809\n",
            "(torch.inverse):  0.004354079564412435 ± 0.005456197927111142\n",
            "GMRES (torch):  0.05166157086690267 ± 0.004782051975264331\n",
            "Schulz Time:  0.002028783162434896 ± 0.0018044376026656857\n",
            "\n",
            "-->> Speedup Ratio\n",
            "GMRES(scipy)/ge = 148.64720863570008%\n",
            "GMRES(torch)/ge = 692.7027055827286%\n",
            "Schulz/ge = 27.202881408309626%\n",
            "\n",
            "GMRES(scipy)/ge = 254.61332067826314%\n",
            "GMRES(torch)/fge = 1186.5095734389547%\n",
            "Schulz/fge = 46.59499516308614%\n",
            "\n",
            "-->> Error\n",
            "FGE (torch.inverse):  3.025780775563666e-11 ± 3.078660649404988e-12\n",
            "GMRES (scipy):  3.5053756722312107e-10 ± 1.188411248096616e-10\n",
            "GMRES (torch):  1.2541734690785233e-10 ± 4.181910587126118e-11\n",
            "Schulz:  4.29863784271826e-11 ± 5.151327097528642e-12\n",
            "=============================\n",
            "Dimension:  64\n",
            "Gaussian Elimination Time:  0.08165693283081055\n",
            "GMRES(scipy) Time:  0.01975107192993164\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.018323183059692383\n",
            "GMRES(torch) Time:  0.28111839294433594\n",
            "Schulz Time:  0.0009703636169433594\n",
            "(torch.inverse) Error:  9.586093483449076e-11\n",
            "GMRES (scipy) Error:  1.0376824152652193e-09\n",
            "Schulz Error:  1.490022782490996e-10\n",
            "GMRES (torch) Error:  1.5593610669384362e-10\n",
            "Gaussian Elimination Time:  0.08128166198730469\n",
            "GMRES(scipy) Time:  0.018723726272583008\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.0004019737243652344\n",
            "GMRES(torch) Time:  0.27412962913513184\n",
            "Schulz Time:  0.0009024143218994141\n",
            "(torch.inverse) Error:  8.9342296405448e-11\n",
            "GMRES (scipy) Error:  9.125003075163098e-10\n",
            "Schulz Error:  1.3954575024399674e-10\n",
            "GMRES (torch) Error:  1.8337834717385703e-10\n",
            "Gaussian Elimination Time:  0.07962369918823242\n",
            "GMRES(scipy) Time:  0.01874828338623047\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.0002949237823486328\n",
            "GMRES(torch) Time:  0.27855610847473145\n",
            "Schulz Time:  0.0010464191436767578\n",
            "(torch.inverse) Error:  7.529787922067043e-11\n",
            "GMRES (scipy) Error:  9.915842432561515e-10\n",
            "Schulz Error:  1.4227189240045845e-10\n",
            "GMRES (torch) Error:  1.4198769804352195e-10\n",
            "====== Summary on Dim 64 ======\n",
            "-->> Time Cost (s)\n",
            "Gaussian Elimination:  0.08085409800211589 ± 0.0008834092982684661\n",
            "GMRES (scipy):  0.019074360529581707 ± 0.0004786122316868155\n",
            "(torch.inverse):  0.00634002685546875 ± 0.008473483714255861\n",
            "GMRES (torch):  0.2779347101847331 ± 0.0028867867686316255\n",
            "Schulz Time:  0.0009730656941731771 ± 5.8820762149647236e-05\n",
            "\n",
            "-->> Speedup Ratio\n",
            "GMRES(scipy)/ge = 23.59108690951267%\n",
            "GMRES(torch)/ge = 343.74845190587587%\n",
            "Schulz/ge = 1.2034834575085023%\n",
            "\n",
            "GMRES(scipy)/ge = 300.8561472121942%\n",
            "GMRES(torch)/fge = 4383.80966706779%\n",
            "Schulz/fge = 15.347974328118735%\n",
            "\n",
            "-->> Error\n",
            "FGE (torch.inverse):  8.683370348686973e-11 ± 8.580193970908531e-12\n",
            "GMRES (scipy):  9.80588988679227e-10 ± 5.169340217425195e-11\n",
            "GMRES (torch):  1.604340506370742e-10 ± 1.7194380548015498e-11\n",
            "Schulz:  1.436066402978516e-10 ± 3.974304504356313e-12\n",
            "=============================\n",
            "Dimension:  256\n",
            "Gaussian Elimination Time:  1.2093746662139893\n",
            "GMRES(scipy) Time:  0.13331842422485352\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.0011532306671142578\n",
            "GMRES(torch) Time:  1.5621788501739502\n",
            "Schulz Time:  0.00769352912902832\n",
            "(torch.inverse) Error:  3.99267901229905e-10\n",
            "GMRES (scipy) Error:  1.0174483114584813e-08\n",
            "Schulz Error:  5.665725893777563e-10\n",
            "GMRES (torch) Error:  9.59816861723084e-10\n",
            "Gaussian Elimination Time:  1.3430569171905518\n",
            "GMRES(scipy) Time:  0.13464832305908203\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.0023140907287597656\n",
            "GMRES(torch) Time:  1.6900060176849365\n",
            "Schulz Time:  0.0013968944549560547\n",
            "(torch.inverse) Error:  3.792506277022767e-10\n",
            "GMRES (scipy) Error:  9.787688823242394e-09\n",
            "Schulz Error:  5.347169462766033e-10\n",
            "GMRES (torch) Error:  1.0042230314866174e-09\n",
            "Gaussian Elimination Time:  1.2280116081237793\n",
            "GMRES(scipy) Time:  0.13451385498046875\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.00098419189453125\n",
            "GMRES(torch) Time:  1.6673595905303955\n",
            "Schulz Time:  0.0013585090637207031\n",
            "(torch.inverse) Error:  4.0520094444218556e-10\n",
            "GMRES (scipy) Error:  1.0742903315607966e-08\n",
            "Schulz Error:  5.415009127318627e-10\n",
            "GMRES (torch) Error:  7.149609700718429e-10\n",
            "====== Summary on Dim 256 ======\n",
            "-->> Time Cost (s)\n",
            "Gaussian Elimination:  1.2601477305094402 ± 0.0591173061408687\n",
            "GMRES (scipy):  0.13416020075480142 ± 0.0005977520170437758\n",
            "(torch.inverse):  0.0014838377634684246 ± 0.0005911195685253484\n",
            "GMRES (torch):  1.6398481527964275 ± 0.055693240721610866\n",
            "Schulz Time:  0.003482977549235026 ± 0.002977350815086003\n",
            "\n",
            "-->> Speedup Ratio\n",
            "GMRES(scipy)/ge = 10.64638672963879%\n",
            "GMRES(torch)/ge = 130.13142134799432%\n",
            "Schulz/ge = 0.2763943833654298%\n",
            "\n",
            "GMRES(scipy)/ge = 9041.433238712441%\n",
            "GMRES(torch)/fge = 110513.97889775588%\n",
            "Schulz/fge = 234.72765250923888%\n",
            "\n",
            "-->> Error\n",
            "FGE (torch.inverse):  3.945731577914557e-10 ± 1.1102107808581373e-11\n",
            "GMRES (scipy):  1.0235025084478391e-08 ± 3.9230742978371004e-10\n",
            "GMRES (torch):  8.930002877605148e-10 ± 1.2719139373545892e-10\n",
            "Schulz:  5.475968161287408e-10 ± 1.3700742753954651e-11\n",
            "=============================\n",
            "Dimension:  1024\n",
            "Gaussian Elimination Time:  19.091475248336792\n",
            "GMRES(scipy) Time:  4.158899784088135\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.004840373992919922\n",
            "GMRES(torch) Time:  11.22643494606018\n",
            "Schulz Time:  0.008754968643188477\n",
            "(torch.inverse) Error:  2.1159507014090196e-09\n",
            "GMRES (scipy) Error:  1.731261257100866e-08\n",
            "Schulz Error:  2.554114144004416e-09\n",
            "GMRES (torch) Error:  3.6422723496798426e-09\n",
            "Gaussian Elimination Time:  19.86177086830139\n",
            "GMRES(scipy) Time:  4.162761688232422\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.004743814468383789\n",
            "GMRES(torch) Time:  11.49289083480835\n",
            "Schulz Time:  0.0018463134765625\n",
            "(torch.inverse) Error:  2.125440551026259e-09\n",
            "GMRES (scipy) Error:  1.3191511385933006e-08\n",
            "Schulz Error:  2.523297916923184e-09\n",
            "GMRES (torch) Error:  3.7199995858827606e-09\n",
            "Gaussian Elimination Time:  19.566911935806274\n",
            "GMRES(scipy) Time:  4.085553407669067\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.004774332046508789\n",
            "GMRES(torch) Time:  11.141587018966675\n",
            "Schulz Time:  0.001354217529296875\n",
            "(torch.inverse) Error:  2.1576470317086206e-09\n",
            "GMRES (scipy) Error:  1.6205221924920392e-08\n",
            "Schulz Error:  2.599393337732181e-09\n",
            "GMRES (torch) Error:  3.723623012774624e-09\n",
            "====== Summary on Dim 1024 ======\n",
            "-->> Time Cost (s)\n",
            "Gaussian Elimination:  19.50671935081482 ± 0.3173391414035641\n",
            "GMRES (scipy):  4.135738293329875 ± 0.03552107953967748\n",
            "(torch.inverse):  0.004786173502604167 ± 4.0299714692994003e-05\n",
            "GMRES (torch):  11.286970933278402 ± 0.14967085458341314\n",
            "Schulz Time:  0.003985166549682617 ± 0.0033787373000119902\n",
            "\n",
            "-->> Speedup Ratio\n",
            "GMRES(scipy)/ge = 21.20160863009043%\n",
            "GMRES(torch)/ge = 57.861964025267696%\n",
            "Schulz/ge = 0.020429711823972862%\n",
            "\n",
            "GMRES(scipy)/ge = 86410.12054994686%\n",
            "GMRES(torch)/fge = 235824.52510626995%\n",
            "Schulz/fge = 83.26414718384697%\n",
            "\n",
            "-->> Error\n",
            "FGE (torch.inverse):  2.1330127613813e-09 ± 1.7844696081452294e-11\n",
            "GMRES (scipy):  1.5569781960620687e-08 ± 1.7413991894603791e-09\n",
            "GMRES (torch):  3.6952983161124093e-09 ± 3.7524189022468466e-11\n",
            "Schulz:  2.558935132886594e-09 ± 3.125230356710953e-11\n",
            "=============================\n",
            "Dimension:  4096\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.029577255249023438\n",
            "GMRES(torch) Time:  124.32706570625305\n",
            "Schulz Time:  0.0025997161865234375\n",
            "Schulz Error:  1.7323778592981398e-08\n",
            "GMRES (torch) Error:  1.5161626506596805e-07\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.029641151428222656\n",
            "GMRES(torch) Time:  123.2834541797638\n",
            "Schulz Time:  0.00176239013671875\n",
            "Schulz Error:  1.746252382872626e-08\n",
            "GMRES (torch) Error:  1.5290292212739586e-07\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.02960038185119629\n",
            "GMRES(torch) Time:  123.72493624687195\n",
            "Schulz Time:  0.0011785030364990234\n",
            "Schulz Error:  1.7457941430620848e-08\n",
            "GMRES (torch) Error:  1.509829075075686e-07\n",
            "====== Summary on Dim 4096 ======\n",
            "-->> Time Cost (s)\n",
            "(torch.inverse):  0.02960626284281413 ± 2.6414894483624e-05\n",
            "GMRES (torch):  123.7784853776296 ± 0.42773191495685287\n",
            "Schulz Time:  0.0018468697865804036 ± 0.0005832748425234539\n",
            "\n",
            "-->> Speedup Ratio\n",
            "GMRES(torch)/fge = 418082.0998408194%\n",
            "Schulz/fge = 6.238105080623729%\n",
            "\n",
            "-->> Error\n",
            "GMRES (torch):  1.5183403156697748e-07 ± 7.988244370360895e-10\n",
            "Schulz:  1.7414747950776172e-08 ± 6.435224749400197e-11\n",
            "=============================\n",
            "Dimension:  16384\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.7697114944458008\n",
            "GMRES(torch) Time:  675.0680797100067\n",
            "Schulz Time:  0.045127153396606445\n",
            "Schulz Error:  0.617094287109375\n",
            "GMRES (torch) Error:  60.23031875\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.7716114521026611\n",
            "GMRES(torch) Time:  673.2860383987427\n",
            "Schulz Time:  0.003943443298339844\n",
            "Schulz Error:  0.617777392578125\n",
            "GMRES (torch) Error:  60.2271875\n",
            "Faster Gaussian Elimination Time (torch.inverse):  0.7728750705718994\n",
            "GMRES(torch) Time:  667.5533528327942\n",
            "Schulz Time:  0.002739429473876953\n",
            "Schulz Error:  0.61674716796875\n",
            "GMRES (torch) Error:  60.2283\n",
            "====== Summary on Dim 16384 ======\n",
            "-->> Time Cost (s)\n",
            "(torch.inverse):  0.7713993390401205 ± 0.0013002044556865153\n",
            "GMRES (torch):  671.9691569805145 ± 3.206078862830317\n",
            "Schulz Time:  0.017270008722941082 ± 0.019704107767155497\n",
            "\n",
            "-->> Speedup Ratio\n",
            "GMRES(torch)/fge = 87110.41388973311%\n",
            "Schulz/fge = 2.2387896707859207%\n",
            "\n",
            "-->> Error\n",
            "GMRES (torch):  60.22860208333333 ± 0.0012960510267317428\n",
            "Schulz:  0.6172062825520833 ± 0.0004279781309296734\n",
            "=============================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import json\n",
        "import time\n",
        "from scipy.sparse.linalg import gmres\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"DEVICE: \", device)\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "def schulz_inverse_stable(A, damping_factor=0.001, max_iterations=20, tol=1e-6, X_0_const=0.00005):\n",
        "    n = A.shape[0]\n",
        "    I = torch.eye(n, device=A.device, dtype=A.dtype)\n",
        "    A = A + damping_factor * I\n",
        "    X = torch.eye(n, device=A.device) * X_0_const\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        X = X @ (2 * I - A @ X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "d = [16,64,256,1024,4096,16384]\n",
        "# d = [4096]\n",
        "Ns = 12800\n",
        "damping_factor = 0.1\n",
        "\n",
        "result_dict = {\n",
        "    \"dim\": d,\n",
        "    \"ge_time\": [],\n",
        "    \"fge_time\": [],\n",
        "    \"schulz_time\": [],\n",
        "    \"gmres_scipy_time\": [],\n",
        "    \"gmres_torch_time\": [],\n",
        "}\n",
        "\n",
        "for dim in d:\n",
        "    ge_time = []\n",
        "    fge_time = []\n",
        "    schulz_time = []\n",
        "    gmres_time = []\n",
        "    gmres_torch_time = []\n",
        "\n",
        "    schulz_errors = []\n",
        "    gmres_errors = []\n",
        "    gmres_torch_errors = []\n",
        "    fge_errors = []\n",
        "    print(\"Dimension: \", dim)\n",
        "\n",
        "    if dim == 16384:\n",
        "        damping_factor = 1.0 ## make sure it is invertible\n",
        "        x0_const = 0.000005\n",
        "    else:\n",
        "        damping_factor = 0.1\n",
        "        x0_const = 0.00005\n",
        "\n",
        "\n",
        "    for seed in range(3):\n",
        "        set_seed(seed=seed)\n",
        "        time_schulz = 0\n",
        "        time_inv = 0\n",
        "\n",
        "        A = torch.zeros((dim, dim)).to(device)\n",
        "        for _ in range(Ns):\n",
        "            tmp = torch.randn((dim, 1)).to(device)\n",
        "            A += tmp @ tmp.T\n",
        "\n",
        "        I = torch.eye(dim, device=A.device)\n",
        "        A = A + damping_factor * I\n",
        "\n",
        "        if dim <= 1024:\n",
        "            st_time = time.time()\n",
        "            ## Exact Inverse by Gaussian Elimination\n",
        "            A_inv_ge = gaussian_elimination_inverse(A)\n",
        "            time_ge = time.time() - st_time\n",
        "            print(\"Gaussian Elimination Time: \", time_ge)\n",
        "            ge_time.append(time_ge)\n",
        "\n",
        "            st_time = time.time()\n",
        "            ## Compute inverse by GMRES (scipy.linalg.gmres)\n",
        "            A_inv_gmres_scipy = scipy_gmres_inverse(A.cpu().numpy(), tol=1e-6, maxiter=20)\n",
        "            time_gmres = time.time() - st_time\n",
        "            print(\"GMRES(scipy) Time: \", time_gmres)\n",
        "            gmres_time.append(time_gmres)\n",
        "\n",
        "        st_time = time.time()\n",
        "        ## Faster Gaussian Elimination by (torch.inverse)\n",
        "        A_inv = torch.inverse(A)\n",
        "        time_inv = time.time() - st_time\n",
        "        print(\"Faster Gaussian Elimination Time (torch.inverse): \", time_inv)\n",
        "        fge_time.append(time_inv)\n",
        "\n",
        "        st_time = time.time()\n",
        "        ## Compute inverse by GMRES (rewrite in pytorch, enable GPU acceleration)\n",
        "        A_inv_gmres_torch = pytorch_gmres_inverse(A, tol=1e-6, maxiter=20)\n",
        "        time_gmres_torch = time.time() - st_time\n",
        "        print(\"GMRES(torch) Time: \", time_gmres_torch)\n",
        "        gmres_torch_time.append(time_gmres_torch)\n",
        "\n",
        "        st_time = time.time()\n",
        "        ## Compute inverse by Schulz method\n",
        "        A_inv_schulz = schulz_inverse_stable(A, damping_factor=0, max_iterations=20, tol=1e-6, X_0_const=x0_const)\n",
        "        time_schulz = time.time() - st_time\n",
        "        print(\"Schulz Time: \", time_schulz)\n",
        "        schulz_time.append(time_schulz)\n",
        "\n",
        "        ## compute the approximation errors by Frobenius distance\n",
        "        if dim <= 1024:\n",
        "            fge_error = torch.norm(A_inv_ge*1e4 - A_inv*1e4, p='fro').item() /1e4\n",
        "            fge_errors.append(fge_error)\n",
        "            print(\"(torch.inverse) Error: \", fge_error)\n",
        "\n",
        "            gmres_scipy_error = np.linalg.norm(A_inv_ge.cpu().numpy()*1e4 - A_inv_gmres_scipy*1e4, ord='fro').item() /1e4\n",
        "            gmres_errors.append(gmres_scipy_error)\n",
        "            print(\"GMRES (scipy) Error: \", gmres_scipy_error)\n",
        "\n",
        "            sc_error = torch.norm(A_inv_ge*1e4 - A_inv_schulz*1e4, p='fro').item() /1e4\n",
        "            schulz_errors.append(sc_error)\n",
        "            print(\"Schulz Error: \", sc_error)\n",
        "            gmres_torch_error = torch.norm(A_inv_ge*1e4 - A_inv_gmres_torch*1e4, p='fro').item() /1e4\n",
        "            gmres_torch_errors.append(gmres_torch_error)\n",
        "            print(\"GMRES (torch) Error: \", gmres_torch_error)\n",
        "        else:\n",
        "            sc_error = torch.norm(A_inv*1e4 - A_inv_schulz*1e4, p='fro').item() /1e4\n",
        "            schulz_errors.append(sc_error)\n",
        "            print(\"Schulz Error: \", sc_error)\n",
        "            gmres_torch_error = torch.norm(A_inv*1e4 - A_inv_gmres_torch*1e4, p='fro').item() /1e4\n",
        "            gmres_torch_errors.append(gmres_torch_error)\n",
        "            print(\"GMRES (torch) Error: \", gmres_torch_error)\n",
        "\n",
        "\n",
        "    ## take the average of the times\n",
        "    print(f\"====== Summary on Dim {dim} ======\")\n",
        "    print(\"-->> Time Cost (s)\")\n",
        "    if dim <= 1024:\n",
        "      result_dict[\"ge_time\"].append(np.mean(ge_time))\n",
        "      result_dict[\"gmres_scipy_time\"].append(np.mean(gmres_time))\n",
        "      print(\"Gaussian Elimination: \", np.mean(ge_time), \"±\", np.std(ge_time))\n",
        "      print(\"GMRES (scipy): \", np.mean(gmres_time), \"±\", np.std(gmres_time))\n",
        "\n",
        "    result_dict[\"fge_time\"].append(np.mean(fge_time))\n",
        "    result_dict[\"schulz_time\"].append(np.mean(schulz_time))\n",
        "    result_dict[\"gmres_torch_time\"].append(np.mean(gmres_torch_time))\n",
        "    print(\"(torch.inverse): \", np.mean(fge_time), \"±\", np.std(fge_time))\n",
        "    print(\"GMRES (torch): \", np.mean(gmres_torch_time), \"±\", np.std(gmres_torch_time))\n",
        "    print(\"Schulz Time: \", np.mean(schulz_time), \"±\", np.std(schulz_time))\n",
        "    print()\n",
        "\n",
        "    print(\"-->> Speedup Ratio\")\n",
        "    if dim <= 1024:\n",
        "        print(f\"GMRES(scipy)/ge = {100*np.mean(gmres_time)/np.mean(ge_time)}%\")\n",
        "        print(f\"GMRES(torch)/ge = {100*np.mean(gmres_torch_time)/np.mean(ge_time)}%\")\n",
        "        print(f\"Schulz/ge = {100*np.mean(schulz_time)/np.mean(ge_time)}%\")\n",
        "        print()\n",
        "        print(f\"GMRES(scipy)/ge = {100*np.mean(gmres_time)/np.mean(fge_time)}%\")\n",
        "    print(f\"GMRES(torch)/fge = {100*np.mean(gmres_torch_time)/np.mean(fge_time)}%\")\n",
        "    print(f\"Schulz/fge = {100*np.mean(schulz_time)/np.mean(fge_time)}%\")\n",
        "    print()\n",
        "\n",
        "    print(\"-->> Error\")\n",
        "    if dim <= 1024:\n",
        "        print(\"FGE (torch.inverse): \", np.mean(fge_errors), \"±\", np.std(fge_errors))\n",
        "        print(\"GMRES (scipy): \", np.mean(gmres_errors), \"±\", np.std(gmres_errors))\n",
        "    print(\"GMRES (torch): \", np.mean(gmres_torch_errors), \"±\", np.std(gmres_torch_errors))\n",
        "    print(\"Schulz: \", np.mean(schulz_errors), \"±\", np.std(schulz_errors))\n",
        "    print(\"=============================\")\n",
        "\n",
        "\n",
        "## take the average of the times\n",
        "#print(\"Exact Time: \", np.mean(exact_time), \"±\", np.std(exact_time))\n",
        "#print(\"Schulz Time: \", np.mean(schulz_time), \"±\", np.std(schulz_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPUASzuYxLYy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
